**Feedback and Decisions**

Many people suggested that we work with Kinect first and then see if we needed to implement OpenCV for our purposes afterwards. The majority also recommended that we split up our work into multiple files rather than condensing it into one massive file, so we will make files for the Kinect elements and the OpenCV elements separately. One of the most important things we got out of the review were the resources that people referred us to, including human resources and useful libraries such as PCL Library. We have already taken the first piece of advice into account, having interfaced the Kinect with python already with the plan to implement OpenCV afterwards. We have some questions about point clouds and skeletal tracking using the Kinect that we will look more into. We would need to learn more about rigging the skeletal tracking to an 2D image or a 3D dimensional model, and figure out whether to uses the Kinectâ€™s infrared camera to help with tracking the motion. 





**Review Process Reflection** 

The review went pretty well; we got many different opinions on whether to use OpenCV or Kinect or a combination of both, which we were able to parse through and come to a final decision. We decided to initially start with Kinect because we felt like the depth analysis was better to start with. We also felt more confident in this because someone had referred us to Jeff Pflueger, who was doing a Kinect project in the RoboLab, so we knew we had a reliable resource to ask questions. We believe we gave just the right amount of context because people gave us very concrete answers to our questions and could justify their comments. We stuck mainly to our agenda; however, we could have put more diagrams in our slides so the audience could easily visualize what we were trying to convey for a more effective technical review. 
